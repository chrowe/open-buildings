{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"open-buildings","text":"<p>Tools for working with open building datasets</p> <ul> <li>Free software: Apache Software License 2.0</li> <li>Documentation: https://opengeos.github.io/open-buildings</li> <li>Creator: Chris Holmes</li> </ul>"},{"location":"#introduction","title":"Introduction","text":"<p>This repo is intended to be a set of useful scripts for working with Open Building Datasets, Initially Google's Open Buildings dataset and Overture's building dataset, specifically to help translate them into Cloud Native Geospatial formats and then use those. The outputs will live on https://beta.source.coop, here for Google and here for Overture so most people can just make use of those directly. </p> <p>The main operation that most people will be interested in is the 'get-buildings' command, that lets you supply a GeoJSON file to a command-line interface and it'll download all buildings in the area supplied, output in common GIS formats (GeoPackage, FlatGeobuf, Shapefile, GeoJSON and GeoParquet).</p> <p>The rest of the CLI's and scripts are intended to show the process of transforming the data,  and then they've expanded to be a way to benchmark performance.</p> <p>This is basically my first Python project, and certainly my first open source one. It is only possible due to ChatGPT, as I'm not a python programmer, and not a great programmer in general (coded professionally for about 2 years, then shifted to doing lots of other stuff). So it's likely not great code, but it's been fun to iterate on it and seems like it might be useful to others. And contributions are welcome! I'm working on making the issue tracker accessible, so anyone who wants to try out some open source coding can jump in.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install with pip:</p> <pre><code>pip install open-buildings\n</code></pre> <p>This should add a CLI that you can then use. If it's working then:</p> <pre><code>ob\n</code></pre> <p>Should print out a help message. You then should be able run the CLI (download 1.json:</p> <pre><code>ob tools get_buildings 1.json my-buildings.geojson --country_iso RW\n</code></pre> <p>You can also stream the json in directly in one line:</p> <pre><code>curl https://data.source.coop/cholmes/aois/1.json | ob get_buildings - my-buildings.geojson --country_iso RW\n</code></pre>"},{"location":"#functionality","title":"Functionality","text":""},{"location":"#get_buildings","title":"get_buildings","text":"<p>The main tool for most people is <code>get_buildings</code>. It queries complete global building datasets for the GeoJSON provided, outputting results in common geospatial formats. The  full options and explanation can be found in the <code>--help</code> command:</p> <pre><code>% ob get_buildings --help\nUsage: ob get_buildings [OPTIONS] [GEOJSON_INPUT] [DST]\n\n  Tool to extract buildings in common geospatial formats from large archives\n  of GeoParquet data online. GeoJSON input can be provided as a file or piped\n  in from stdin. If no GeoJSON input is provided, the tool will read from\n  stdin.\n\n  Right now the tool supports two sources of data: Google and Overture. The\n  data comes from Cloud-Native Geospatial distributions on\n  https://source.coop, that are partitioned by admin boundaries and use a\n  quadkey for the spatial index. In time this tool will generalize to support\n  any admin boundary partitioned GeoParquet data, but for now it is limited to\n  the Google and Overture datasets.\n\n  The default output is GeoJSON, in a file called buildings.json. Changing the\n  suffix will change the output format - .shp for shapefile .gpkg for\n  GeoPackage, .fgb for FlatGeobuf and .parquet for GeoParquet, and .json or\n  .geojson for GeoJSON. If your query is all within one country it is strongly\n  recommended to use country_iso to hint to the query engine which country to\n  query, as this  will speed up the query significantly (5-10x). Expect query\n  times of 5-10 seconds for a queries with country_iso and 30-60 seconds\n  without country_iso.\n\n  You can look up the country_iso for a country here:\n  https://github.com/lukes/ISO-3166-Countries-with-Regional-\n  Codes/blob/master/all/all.csv If you get the country wrong you will get zero\n  results. Currently you can only query one country, so if your query crosses\n  country boundaries you should not use country_iso. In future versions of\n  this tool we hope to eliminate the need to hint with the country_iso.\n\nOptions:\n  --source [google|overture]  Dataset to query, defaults to Overture\n  --country_iso TEXT          A 2 character country ISO code to filter the\n                              data by.\n  -s, --silent                Suppress all print outputs.\n  --overwrite                 Overwrite the destination file if it already\n                              exists.\n  --verbose                   Print detailed logs with timestamps.\n  --help                      Show this message and exit.\n</code></pre>"},{"location":"#google-building-processings","title":"Google Building processings","text":"<p>In the google portion of the CLI there are two functions:</p> <ul> <li><code>convert</code> takes as input either a single CSV file or a directory of CSV files, downloaded locally from the Google Buildings dataset. It can write out as GeoParquet, FlatGeobuf, GeoPackage and Shapefile, and can process the data using DuckDB, GeoPandas or OGR.</li> <li><code>benchmark</code> runs the convert command against one or more different formats, and one or more different processes, and reports out how long each took.</li> </ul> <p>A sample output for <code>benchmark</code>, run on 219_buildings.csv, a 101 mb CSV file is:</p> <pre><code>Table for file: 219_buildings.csv\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 process   \u2502 fgb       \u2502 gpkg      \u2502 parquet   \u2502 shp       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 duckdb    \u2502 00:02.330 \u2502 00:00.000 \u2502 00:01.866 \u2502 00:03.119 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ogr       \u2502 00:02.034 \u2502 00:07.456 \u2502 00:01.423 \u2502 00:02.491 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 pandas    \u2502 00:18.184 \u2502 00:24.096 \u2502 00:02.710 \u2502 00:20.032 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</code></pre> <p>The full options can be found with <code>--help</code> after each command, and I'll put them here for reference:</p> <pre><code>Usage: open_buildings convert [OPTIONS] INPUT_PATH OUTPUT_DIRECTORY\n\n  Converts a CSV or a directory of CSV's to an alternate format. Input CSV's\n  are assumed to be from Google's Open Buildings\n\nOptions:\n  --format [fgb|parquet|gpkg|shp]\n                                  The output format. The default is FlatGeobuf (fgb)\n  --overwrite                     Whether to overwrite any existing output files.\n  --process [duckdb|pandas|ogr]   The processing method to use. The default is \n                                  pandas.\n  --skip-split-multis             Whether to keep multipolygons as they are\n                                  without splitting into their component polygons.\n  --verbose                       Whether to print detailed processing\n                                  information.\n  --help                          Show this message and exit.\n</code></pre> <pre><code>Usage: open_buildings benchmark [OPTIONS] INPUT_PATH OUTPUT_DIRECTORY\n\n  Runs the convert function on each of the supplied processes and formats,\n  printing the timing of each as a table\n\nOptions:\n  --processes TEXT      The processing methods to use. One or more of duckdb,\n                        pandas or ogr, in a comma-separated list. Default is\n                        duckdb,pandas,ogr.\n  --formats TEXT        The output formats to benchmark. One or more of fgb,\n                        parquet, shp or gpkg, in a comma-separated list.\n                        Default is fgb,parquet,shp,gpkg.\n  --skip-split-multis   Whether to keep multipolygons as they are without\n                        splitting into their component polygons.\n  --no-gpq              Disable GPQ conversion. Timing will be faster, but not\n                        valid GeoParquet (until DuckDB adds support)\n  --verbose             Whether to print detailed processing information.\n  --output-format TEXT  The format of the output. Options: ascii, csv, json,\n                        chart.\n  --help                Show this message and exit.\n</code></pre> <p>Warning - note that <code>--no-gpq</code> doesn't actually work right now, see https://github.com/opengeos/open-buildings/issues/4 to track. It is just always set to true, so DuckDB times with Parquet will be inflated (you can change it in the Python code in a global variables). Note also that the <code>ogr</code> process does not work with <code>--skip-split-multis</code>, but will just report very minimal times since it skips doing anything, see https://github.com/opengeos/open-buildings/issues/5 to track.</p>"},{"location":"#format-notes","title":"Format Notes","text":"<p>I'm mostly focused on GeoParquet and FlatGeobuf, as good cloud-native geo formats. I included GeoPackage and Shapefile mostly for benchmarking purposes. GeoPackage I think is a good option for Esri and other more legacy software that is slow to adopt new formats. Shapefile is total crap for this use case - it fails on files bigger than 4 gigabytes, and lots of the source S2 Google Building CSV's are bigger, so it's not useful for translating. The truncation of field names is also annoying, since the CSV file didn't try to make short names (nor should it, the limit is silly).</p> <p>GeoPackage is particularly slow with DuckDB, it's likely got a bit of a bug in it. But it works well with Pandas and OGR.</p>"},{"location":"#process-notes","title":"Process Notes","text":"<p>When I was processing V2 of the Google Building's dataset I did most of the initial work with GeoPandas, which was awesome, and has the best GeoParquet implementation. But the size of the data made its all in memory processing untenable. I ended up using PostGIS a decent but, but near the end of that process I discovered DuckDB, and was blown away by it's speed and ability to manage memory well. So for this tool I was mostly focused on those two.</p> <p>Note also that currently DuckDB fgb, gpkg and shp output don't include projection information, so if you want to use the output then you'd need to run ogr2ogr on the output. It sounds like that may get fixed pretty soon, so I'm not going to add a step that includes the ogr conversion.</p> <p>OGR was added later, and as of yet does not yet do the key step of splitting multi-polygons, since it's just using ogr2ogr as a sub-process and I've yet to find a way to do that from the CLI (though knowing GDAL/OGR there probably is one - please let me know). To run the benchmark with it you need to do --skip-split-multis or else the times on it will be 0 (except for Shapefile, since it doesn't differentiate between multipolygons and regular polygons). I hope to add that functionality and get it on par, which may mean using Fiona. But it seems like that may affect performance, since Fiona doesn't use the GDAL/OGR column-oriented API.</p>"},{"location":"#code-customizations","title":"Code customizations","text":"<p>There are 3 options that you can set as global variables in the Python code, but are not yet CLI options. These are:</p> <ul> <li><code>RUN_GPQ_CONVERSION</code> - whether GeoParquet from DuckDB by default runs gpq on the DuckDB Parquet output, which adds a good chunk of processing time. This makes it so the DuckDB processing output is slower than it would be if DuckDB natively wrote GeoParquet metadata, which I believe is on their roadmap. So that will likely emerge as the fastest benchmark time. In the code you can set <code>RUN_GPQ_CONVERSION</code> in the python code to false if you want to get a sense of it. In the above benchmark running the Parquet with DuckDB without GPQ conversion at the end resulted in a time of .76 seconds. </li> <li><code>PARQUET_COMPRESSION</code> - which compression to use for Parquet encoding. Note that not all processes support all compression options, and also the OGR converter currently ignores this option.</li> <li><code>SKIP_DUCK_GPKG</code> - whether to skip the GeoPackage conversion option on DuckDB, since it takes a long time to run.</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>All contributions are welcome, I love running open source projects. I'm clearly just learning to code Python, so there's no judgement about crappy code. And I'm super happy to learn from others about better code. Feel free to sound in on the issues, make new ones, grab one, or make a PR. There's lots of low hanging fruit of things to add. And if you're just starting out programming don't hesitate to ask even basic things in the discussions.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"common/","title":"common module","text":"<p>The common module contains common functions and classes used by the other modules.</p>"},{"location":"common/#open_buildings.common.hello_world","title":"<code>hello_world()</code>","text":"<p>Prints \"Hello World!\" to the console.</p> Source code in <code>open_buildings/common.py</code> <pre><code>def hello_world():\n    \"\"\"Prints \"Hello World!\" to the console.\n    \"\"\"\n    print(\"Hello World!\")\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/opengeos/open-buildings/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>open-buildings could always use more documentation, whether as part of the official open-buildings docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/opengeos/open-buildings/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up open-buildings for local development.</p> <ol> <li> <p>Fork the open-buildings repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/open-buildings.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv open-buildings\n$ cd open-buildings/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 open-buildings tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.5, 3.6, 3.7 and 3.8, and     for PyPy. Check https://github.com/opengeos/open-buildings/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":"<p>To install open-buildings, run this command in your terminal:</p> <pre><code>pip install open-buildings\n</code></pre> <p>This is the preferred method to install open-buildings, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p> <p>This should add a CLI that you can then use. If it's working then:</p> <pre><code>ob\n</code></pre> <p>Should print out a help message. You then should be able run the CLI (download 1.json:</p> <pre><code>ob tools get_buildings 1.json my-buildings.geojson --country_iso RW\n</code></pre> <p>You can also stream the json in directly in one line:</p> <pre><code>curl https://data.source.coop/cholmes/aois/1.json | ob get_buildings - my-buildings.geojson --country_iso RW\n</code></pre>"},{"location":"installation/#install-from-sources","title":"Install From sources","text":"<p>To install open-buildings from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/opengeos/open-buildings\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use open-buildings in a project:</p> <pre><code>import open_buildings\n</code></pre>"},{"location":"examples/download_buildings/","title":"Download buildings","text":"In\u00a0[1]: Copied! <pre># %pip install open-buildings\n</pre> # %pip install open-buildings <p>Iimport libraries</p> In\u00a0[2]: Copied! <pre>import os\nimport leafmap.foliumap as leafmap\nimport geopandas as gpd\n</pre> import os import leafmap.foliumap as leafmap import geopandas as gpd <p>Read the tile geojson.</p> In\u00a0[3]: Copied! <pre>url = 'https://sites.research.google/open-buildings/tiles.geojson'\ngdf = gpd.read_file(url)\ngdf.sort_values(by='size_mb', ascending=True, inplace=True)\ngdf.head()\n</pre> url = 'https://sites.research.google/open-buildings/tiles.geojson' gdf = gpd.read_file(url) gdf.sort_values(by='size_mb', ascending=True, inplace=True) gdf.head() Out[3]: tile_id tile_url size_mb geometry 135 23b https://storage.googleapis.com/open-buildings-... 0.0 POLYGON ((55.49148 -13.74670, 61.32685 -14.599... 321 973 https://storage.googleapis.com/open-buildings-... 0.0 POLYGON ((-84.94013 -22.54055, -84.94013 -28.5... 320 971 https://storage.googleapis.com/open-buildings-... 0.0 POLYGON ((-84.94013 -28.57907, -84.94013 -34.4... 131 225 https://storage.googleapis.com/open-buildings-... 0.0 POLYGON ((50.01877 -12.81566, 55.49148 -13.746... 136 23d https://storage.googleapis.com/open-buildings-... 0.0 POLYGON ((55.49148 -18.94995, 61.32685 -20.080... In\u00a0[4]: Copied! <pre>print(f\"Number of tiles: {len(gdf)}\")\n</pre> print(f\"Number of tiles: {len(gdf)}\") <pre>Number of tiles: 333\n</pre> In\u00a0[5]: Copied! <pre>m = leafmap.Map()\nm.add_gdf(gdf, layer_name=\"Open Buildings\")\nm\n</pre> m = leafmap.Map() m.add_gdf(gdf, layer_name=\"Open Buildings\") m Out[5]: <p>Get the tile URLs.</p> In\u00a0[6]: Copied! <pre>urls = gdf['tile_url'].tolist()\nurls[:5]\n</pre> urls = gdf['tile_url'].tolist() urls[:5] Out[6]: <pre>['https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/23b_buildings.csv.gz',\n 'https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/973_buildings.csv.gz',\n 'https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/971_buildings.csv.gz',\n 'https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/225_buildings.csv.gz',\n 'https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/23d_buildings.csv.gz']</pre> <p>Specify the output directory.</p> In\u00a0[7]: Copied! <pre>out_dir = os.path.expanduser('~/Downloads/')\n</pre> out_dir = os.path.expanduser('~/Downloads/') <p>Download all the tiles might take a while. Let's download only the first 10 tiles.</p> In\u00a0[8]: Copied! <pre>leafmap.download_files(urls[:10], out_dir=out_dir)\n</pre> leafmap.download_files(urls[:10], out_dir=out_dir) <pre>Downloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/23b_buildings.csv.gz\nTo: /home/runner/Downloads/23b_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 39.2k/39.2k [00:00&lt;00:00, 371kB/s]\nDownloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/973_buildings.csv.gz\nTo: /home/runner/Downloads/973_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.22k/4.22k [00:00&lt;00:00, 10.3MB/s]\nDownloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/971_buildings.csv.gz\nTo: /home/runner/Downloads/971_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.15k/6.15k [00:00&lt;00:00, 14.0MB/s]\nDownloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/225_buildings.csv.gz\nTo: /home/runner/Downloads/225_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.48k/9.48k [00:00&lt;00:00, 19.1MB/s]\nDownloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/23d_buildings.csv.gz\nTo: /home/runner/Downloads/23d_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 393/393 [00:00&lt;00:00, 2.37MB/s]\nDownloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/32b_buildings.csv.gz\nTo: /home/runner/Downloads/32b_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.2k/12.2k [00:00&lt;00:00, 23.4MB/s]\nDownloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/39d_buildings.csv.gz\nTo: /home/runner/Downloads/39d_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 16.2k/16.2k [00:00&lt;00:00, 1.94MB/s]\nDownloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/b5b_buildings.csv.gz\nTo: /home/runner/Downloads/b5b_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.5k/14.5k [00:00&lt;00:00, 65.0MB/s]\nDownloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/3ef_buildings.csv.gz\nTo: /home/runner/Downloads/3ef_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 43.6k/43.6k [00:00&lt;00:00, 274kB/s]\nDownloading...\nFrom: https://storage.googleapis.com/open-buildings-data/v3/polygons_s2_level_4_gzip/815_buildings.csv.gz\nTo: /home/runner/Downloads/815_buildings.csv.gz\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 38.7k/38.7k [00:00&lt;00:00, 279kB/s]\n</pre>"},{"location":"examples/intro/","title":"Intro","text":"In\u00a0[1]: Copied! <pre>import open_buildings as ob\n</pre> import open_buildings as ob"}]}